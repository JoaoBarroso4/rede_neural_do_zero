{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeP0HqP6OYdnUbwOKg9yIC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoBarroso4/rede_neural_do_zero/blob/main/Rede_neural_do_zero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mNwioVu9OTRz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor() # convertendo a imagem para tensor\n",
        "\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # carrega o dataset de treino\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # cria um buffer para pegar os dados por partes\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # carrega o dataset de validação\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True) # cria um buffer para pegar os dados por partes"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LWaA9CTvPH2b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "\n",
        "imagens, etiquetas = next(dataiter)\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap=\"gray_r\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "bcZPT2izQkSh",
        "outputId": "4627472e-aca8-4bd6-9144-421ef5ef3e9b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d409338f490>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape) # verificar as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape) # verificar as dimensões do tensor de cada etiqueta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOAeFF6eSLk2",
        "outputId": "4846bba8-1922-424a-a22a-d2895eb2ece9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# valores padrões para a rede inception v3\n",
        "class Modelo(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Modelo, self).__init__()\n",
        "    self.linear1 = nn.Linear(28*28, 128) # camada de entrada, 784 neurônios que se ligam a 128\n",
        "    self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neurônios que se ligam a 64\n",
        "    self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neurônios que se ligam a 10\n",
        "    # não é necessário definir nada para a camada de saída, pois só precisamos pegar o output da camada interna 2\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1\n",
        "    X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para a camada interna 2\n",
        "    X = self.linear3(X) # função de ativação da camada interna 2 para a camada de saída. nesse caso, f(x) = x\n",
        "    return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"
      ],
      "metadata": {
        "id": "fdV1oRMoSu8r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainLoader, device):\n",
        "\n",
        "  otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a política de atualização dos pesos e bias\n",
        "  inicio = time() # timer para sabermos quanto tempo durou o treino\n",
        "\n",
        "  criterio = nn.NLLLoss() # definindo o criterio para calcular a perda\n",
        "  EPOCHS = 10 # número de epochs que o algoritmo rodará (ideal ~ 100)\n",
        "  modelo.train()\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    perda_acumulada = 0 # inicialização da perda acumulada da epoch em questão\n",
        "\n",
        "    for imagens, etiquetas in trainloader:\n",
        "\n",
        "      imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens para \"vetores\" de 28*28 casas para ficarem compatíveis com a\n",
        "      otimizador.zero_grad() # zerando os gradientes por conta do ciclo anterior\n",
        "\n",
        "      output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
        "      perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
        "\n",
        "      perda_instantanea.backward() # back propagation a partir da perda\n",
        "\n",
        "      otimizador.step() # atualizando os pesos e bias\n",
        "\n",
        "      perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
        "\n",
        "    else:\n",
        "      print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "  print(\"\\nTempo de treino (em minutos) = \", (time() - inicio)/60)"
      ],
      "metadata": {
        "id": "XpPvtdZPUoyk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "  conta_corretas, conta_todas = 0, 0\n",
        "\n",
        "  for imagens, etiquetas in valloader:\n",
        "    for i in range(len(etiquetas)):\n",
        "      img = imagens[i].view(1, 784)\n",
        "      # desativar o autograd para acelerar a validação. grafos computacionais dinâmicos têm um custo de alto processamento\n",
        "      with torch.no_grad():\n",
        "        logps = modelo(img.to(device)) # output do modelo em escala logarítmica\n",
        "\n",
        "\n",
        "      ps = torch.exp(logps) # converte o output para escala normal (lembrete: é um tensor)\n",
        "      probab = list(ps.cpu().numpy()[0])\n",
        "      etiqueta_pred = probab.index(max(probab)) # converte o tensor em um número, no caso, o número que o modelo previu\n",
        "      etiqueta_certa = etiquetas.numpy()[i]\n",
        "      if(etiqueta_certa == etiqueta_pred):\n",
        "        conta_corretas += 1\n",
        "      conta_todas += 1\n",
        "\n",
        "  print(\"Total de imagens testadas =\", conta_todas)\n",
        "  print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todas))"
      ],
      "metadata": {
        "id": "3qK05G4UYuwB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo() # incializa o modelo\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3MxBFUibT40",
        "outputId": "a69b1614-0f58-48fc-a874-4ac485a779e9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}